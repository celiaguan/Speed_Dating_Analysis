{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis for topic #crypto\n",
    "## Celia Guan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://dev.to/rodolfoferro/sentiment-analysis-on-trumpss-tweets-using-python-\n",
    "\n",
    "https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "\n",
    "https://stackoverflow.com/questions/43646877/python-extract-positive-words-from-a-string-using-sentiment-vader\n",
    "\n",
    "https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\n",
    "\n",
    "https://saadbinakhlaq.wordpress.com/2012/05/27/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "\n",
    "https://pythonspot.com/nltk-stop-words/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation \n",
    "* install tweepy, nltk, and vaderSentiment\n",
    "* create a new Tweeter App to get credential info from [here](https://apps.twitter.com/).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy                        # To consume Twitter's API\n",
    "import nltk\n",
    "from tweepy import OAuthHandler\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keys and tokens from my own Twitter Dev Console\n",
    "consumer_key = 'U8r9YwyzRDxsOtzbvY1Cft2DN'\n",
    "consumer_secret = 'haQeaScBqr5p8KeqHlllV6j9xOCkyTTrAXubzALNt7ZFcAuND6'\n",
    "access_token = '248897528-iPVEIMz4AXvBgzGaOaxCya2cZRvUwJB1CmAGjdZ2'\n",
    "access_token_secret = 'mo31PDQkxtrL3hrmyxtTkwCsP1Eq7ddx0Q9we3wMOc64P'\n",
    " \n",
    "# create OAuthHandler object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# set access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# create tweepy API object to fetch tweets\n",
    "api = tweepy.API(auth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets extracted: 99.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fetch the tweets from hashtag, max 100 tweets per fetch\n",
    "fetch_tweets = api.search('crypto', since = '2018-01-07', until = '2018-01-08', count=100)\n",
    "# verify the size\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(fetch_tweets)))\n",
    "# fetch another 5 times to get more tweets\n",
    "fetch_tweets2 = api.search('crypto', since = '2018-01-09', until = '2018-01-10', count=100)\n",
    "fetch_tweets3 = api.search('crypto', since = '2018-01-11', until = '2018-01-12', count=100)\n",
    "fetch_tweets4 = api.search('crypto', since = '2018-01-13', until = '2018-01-14', count=100)\n",
    "fetch_tweets5 = api.search('crypto', since = '2018-01-14', until = '2018-01-15', count=100)\n",
    "fetch_tweets6 = api.search('crypto', since = '2018-01-15', until = '2018-01-16', count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RT',\n",
       "  '@',\n",
       "  'CryptonyteNews',\n",
       "  ':',\n",
       "  'Tron',\n",
       "  'ðŸ’¸',\n",
       "  '$',\n",
       "  'TRX',\n",
       "  '$',\n",
       "  '0.20',\n",
       "  'and',\n",
       "  'rising',\n",
       "  'ðŸš€',\n",
       "  '#',\n",
       "  'crypto',\n",
       "  '#',\n",
       "  'jointhecoin',\n",
       "  '#',\n",
       "  'btc',\n",
       "  '#',\n",
       "  'ltc',\n",
       "  '#',\n",
       "  'eth',\n",
       "  '#',\n",
       "  'xrp',\n",
       "  '#',\n",
       "  'xvg',\n",
       "  'https',\n",
       "  ':',\n",
       "  '//t.co/v3lz3Ex6XN']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize each tweet into words and make them into a list\n",
    "tweets1 = []\n",
    "for tweet in fetch_tweets + fetch_tweets2 + fetch_tweets3 + fetch_tweets4 + fetch_tweets5 + fetch_tweets6:\n",
    "    tweets1.append(word_tokenize(tweet.text))\n",
    "# first tweets\n",
    "tweets1[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets extracted: 589.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# size of the data \n",
    "print(\"Total number of tweets extracted: {}.\\n\".format(len(tweets1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_word_list=[]\n",
    "stop_word_list=[]\n",
    "neg_word_list=[]\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "for obj in tweets1:\n",
    "    for word in obj:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            neg_word_list.append(word)\n",
    "        elif(word in stopWords):\n",
    "            stop_word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Won',\n",
       " 'fun',\n",
       " 'award',\n",
       " 'honest',\n",
       " 'rewarding',\n",
       " 'Best',\n",
       " 'happy',\n",
       " 'great',\n",
       " 'bonus',\n",
       " 'Euphoria']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 positive words\n",
    "pos_word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frustrated',\n",
       " 'WAR',\n",
       " 'Fuck',\n",
       " 'dumb',\n",
       " 'numbskull',\n",
       " 'illegal',\n",
       " 'illegal',\n",
       " 'fascist',\n",
       " 'retarded',\n",
       " 'hating']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 negative words\n",
    "neg_word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'that', 's', 'of', 'when', 'we', 'to', 'or', 'is', 'be']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 stop words\n",
    "stop_word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of positive to negative words: 3.90.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The ratio of positive to negative words: {0:.2f}.\\n\".format(len(pos_word_list)/len(neg_word_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is your interpretation of the ratio?\n",
    "* The number of positive words is more than triple that of the negative words \n",
    "* Most people are optimistic about crypto at least when talking about it \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the managerial insight that you could offer based on your results?\n",
    "* Be careful and prudent when evaluate products, medium, investment and services that are related to crypto because they tend to look more promising \n",
    "* Take advantage of this trend to sale related products and services becuase they tend to get more positive feedback from the pulic than the oposite\n",
    "* With other evaluations, consider reasonably increasing investment on crypto technologies \n",
    "* Closely follow new crypto research "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
